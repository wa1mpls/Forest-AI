# -*- coding: utf-8 -*-
"""forest AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rGU4I-aIlZEEl79XDN2FeHK539RaP6eo

#Cài đặt môi trường
"""

!pip install torch torchvision transformers geemap datasets earthengine-api

"""#Cài đặt thư viện"""

import ee
import torch
import torchvision.transforms as transforms
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from torch.utils.data import Dataset, DataLoader, random_split
from transformers import ViTModel
import torch.nn as nn
import torch.optim as optim
import geemap
import os
from google.colab import drive

"""#Lấy dữ liệu ảnh vệ tinh & dữ liệu thực địa từ Google Earth Engine"""

!pip install earthengine-api geemap

import ee

# Xác thực tài khoản (sẽ hiển thị link, bạn cần đăng nhập vào tài khoản Google để lấy mã)
ee.Authenticate()

# Khởi tạo lại Earth Engine với project ID
ee.Initialize(project='ee-ngonguyenthanhthanh00')

# ✅ Mount Google Drive
drive.mount('/content/drive')
WORKING_DIR = '/content/drive/MyDrive/forest-ai'

# Commented out IPython magic to ensure Python compatibility.
import os

if not os.path.exists(WORKING_DIR):
    os.makedirs(WORKING_DIR)

# %cd $WORKING_DIR

!pip install geemap

"""#Giải pháp thay thế"""

import ee
import geemap

# ✅ Chọn khu vực nghiên cứu (Amazon)
region = ee.Geometry.Rectangle([-75.0, -15.0, -50.0, 5.0])

# ✅ Lọc danh sách bảng GEDI L4A trong khu vực Amazon
gedi_index = ee.FeatureCollection("LARSE/GEDI/GEDI04_A_002_INDEX")
filtered_tables = gedi_index.filterBounds(region)
list_tables = filtered_tables.aggregate_array('table_id').getInfo()

print(f"📌 Tổng số bảng GEDI L4A trong vùng nghiên cứu: {len(list_tables)}")
if len(list_tables) == 0:
    raise ValueError("❌ Không có bảng GEDI nào nằm trong vùng nghiên cứu!")

# ✅ Chọn bảng có nhiều dữ liệu `agbd` nhất
best_table = None
best_count = 0
best_table_name = None

for table_name in list_tables:
    print(f"📌 Đang kiểm tra bảng: {table_name}")

    try:
        temp_table = ee.FeatureCollection(table_name)
        valid_table = temp_table.filter(ee.Filter.notNull(['agbd']))  # 🔹 Chỉ giữ điểm có `agbd`
        valid_count = valid_table.size().getInfo()

        print(f"📌 Số lượng điểm có `agbd`: {valid_count}")

        if valid_count > best_count:
            best_count = valid_count
            best_table = valid_table
            best_table_name = table_name

        if best_count >= 10000:  # Dừng ngay khi có đủ 10.000 điểm
            break

    except Exception as e:
        print(f"❌ Lỗi khi tải bảng {table_name}: {e}")
        continue

# ✅ **Kiểm tra nếu không có bảng nào có dữ liệu**
if best_table is None or best_count == 0:
    raise ValueError("❌ Không có bảng GEDI nào chứa dữ liệu `agbd` trong vùng nghiên cứu!")

print(f"✅ Chọn bảng {best_table_name} có nhiều dữ liệu nhất, với {best_count} điểm.")

# ✅ **Chọn đúng các thuộc tính quan trọng**
selected_columns = [
    'lon_lowestmode_a1',  # Kinh độ
    'lat_lowestmode_a1',  # Vĩ độ
    'agbd',  # Tổng sinh khối
    'agbd_se',  # Độ không chắc chắn của sinh khối
    'l2_quality_flag',  # Cờ chất lượng dữ liệu
    'sensitivity',  # Độ nhạy tín hiệu GEDI
    'landsat_treecover'  # Mật độ tán cây theo Landsat
]

# ✅ **Kiểm tra lại các cột có tồn tại không**
first_feature = best_table.first()
gedi_columns = first_feature.propertyNames().getInfo()
valid_columns = [col for col in selected_columns if col in gedi_columns]
print("📌 Các cột hợp lệ sẽ được xuất:", valid_columns)

# ✅ **Chọn và giới hạn số điểm**
gedi_filtered = best_table.select(valid_columns).limit(10000)

# ✅ **Xuất dữ liệu ra Google Drive**
output_path = "/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv"
geemap.ee_export_vector(gedi_filtered, filename=output_path)

print(f"✅ Xuất dữ liệu thành công! File được lưu tại: {output_path}")

"""#Tiền xử lý dữ liệu"""

import os
print(os.getcwd())  # In ra đường dẫn thư mục hiện tại

import os
print(os.listdir())  # Liệt kê tất cả các file trong thư mục

import os
print(os.path.exists("GEDI_L4A_Amazon.csv"))  # Nếu True thì file có tồn tại, False thì chưa có file

import torch
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# ✅ Đọc dữ liệu
df = pd.read_csv("/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv")

# ✅ Kiểm tra kích thước dữ liệu trước khi dropna
print("📌 Kích thước dữ liệu ban đầu:", df.shape)

# ✅ Chỉ drop NaN trong cột target, không drop toàn bộ
df = df.dropna(subset=['agbd'])

# ✅ Kiểm tra nếu file rỗng
if df.shape[0] == 0:
    raise ValueError("❌ Dữ liệu rỗng! Kiểm tra file CSV hoặc dropna() đã xóa hết dữ liệu.")

print("📌 Kích thước dữ liệu sau khi xử lý:", df.shape)

# ✅ Chọn đặc trưng và nhãn
features = ['lon_lowestmode_a1', 'lat_lowestmode_a1', 'agbd', 'agbd_se', 'l2_quality_flag', 'sensitivity', 'landsat_treecover']
target = 'agbd'

# ✅ Kiểm tra nếu các cột có tồn tại không
for col in features + [target]:
    if col not in df.columns:
        raise ValueError(f"❌ Cột '{col}' không tồn tại trong dữ liệu!")

# ✅ Chia dữ liệu
X = df[features].values
y = df[target].values
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# ✅ Chuyển đổi thành Tensor
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)
y_valid_tensor = torch.tensor(y_valid, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

print("✅ Dữ liệu đã được xử lý thành công!")

import ee
import geemap
import requests
import os
from PIL import Image
import pandas as pd


# ✅ Đọc dữ liệu GEDI từ CSV
gedi_df = pd.read_csv("/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv")

# ✅ Chọn 100 điểm để kiểm tra trước
gedi_df = gedi_df.sample(n=500, random_state=42)

# ✅ Tạo thư mục lưu ảnh
output_dir = "/content/drive/MyDrive/forest-ai/spectral_images"
os.makedirs(output_dir, exist_ok=True)

# ✅ Cấu hình hiển thị ảnh Sentinel-2
viz_params = {
    "bands": ["B4", "B3", "B2"],  # 🔹 Chọn 3 kênh RGB
    "min": 0,
    "max": 3000,  # 🔹 Chuẩn hóa giá trị pixel
    "gamma": 1.5
}

# ✅ Thêm các thư viện cần thiết
!pip install h5py netCDF4

import h5py
import netCDF4
from datetime import datetime, timedelta

# ✅ Định nghĩa các hàm lấy dữ liệu GEDI
def get_gedi_l4a_data(point, date_range):
    """Lấy dữ liệu GEDI L4A cho một điểm"""
    gedi_l4a = ee.ImageCollection("LARSE/GEDI/GEDI04_A_002_MONTHLY")
    filtered = gedi_l4a.filterBounds(point).filterDate(date_range[0], date_range[1])
    
    # Lấy các thuộc tính quan trọng
    properties = {
        'agbd': filtered.select('agbd').mean(),
        'agbd_se': filtered.select('agbd_se').mean(),
        'l2_quality_flag': filtered.select('l2_quality_flag').mode(),
        'sensitivity': filtered.select('sensitivity').mean(),
        'degrade_flag': filtered.select('degrade_flag').mode(),
        'beam_type': filtered.select('beam_type').mode()
    }
    
    return properties

def get_gedi_l2a_data(point, date_range):
    """Lấy dữ liệu GEDI L2A cho một điểm"""
    gedi_l2a = ee.ImageCollection("LARSE/GEDI/GEDI02_A_002_MONTHLY")
    filtered = gedi_l2a.filterBounds(point).filterDate(date_range[0], date_range[1])
    
    # Lấy các thuộc tính chiều cao
    properties = {
        'rh100': filtered.select('rh100').mean(),
        'rh95': filtered.select('rh95').mean(),
        'rh75': filtered.select('rh75').mean()
    }
    
    return properties

def get_gedi_l2b_data(point, date_range):
    """Lấy dữ liệu GEDI L2B cho một điểm"""
    gedi_l2b = ee.ImageCollection("LARSE/GEDI/GEDI02_B_002_MONTHLY")
    filtered = gedi_l2b.filterBounds(point).filterDate(date_range[0], date_range[1])
    
    # Lấy các thuộc tính độ che phủ
    properties = {
        'cover': filtered.select('cover').mean(),
        'pai': filtered.select('pai').mean()
    }
    
    return properties

# ✅ Cập nhật hàm lấy ảnh Sentinel-2
def get_sentinel_image(lat, lon, output_path, date_range):
    point = ee.Geometry.Point([lon, lat])
    
    # Lấy ảnh Sentinel-2
    image = (
        ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
        .filterBounds(point)
        .filterDate(date_range[0], date_range[1])
        .filter(ee.Filter.lt("CLOUDY_PIXEL_PERCENTAGE", 5))
        .median()
        .clip(point.buffer(2500))
    )
    
    # Lấy dữ liệu GEDI
    gedi_l4a = get_gedi_l4a_data(point, date_range)
    gedi_l2a = get_gedi_l2a_data(point, date_range)
    gedi_l2b = get_gedi_l2b_data(point, date_range)
    
    # Kết hợp tất cả dữ liệu
    all_data = {**gedi_l4a, **gedi_l2a, **gedi_l2b}
    
    try:
        # Lấy ảnh Sentinel-2
        url = image.getThumbURL({"dimensions": "256x256", "region": point.buffer(2500), **viz_params})
        response = requests.get(url, stream=True)
        
        if response.status_code == 200:
            # Lưu ảnh
            with open(output_path, "wb") as f:
                f.write(response.content)
            
            # Lưu metadata GEDI
            metadata_path = output_path.replace('.png', '_metadata.json')
            with open(metadata_path, 'w') as f:
                json.dump(all_data, f)
            
            print(f"✅ Đã lưu {output_path} và metadata")
        else:
            print(f"❌ Không tải được ảnh từ {url}")
            
    except Exception as e:
        print(f"❌ Lỗi khi lấy dữ liệu tại ({lat}, {lon}): {e}")

# ✅ Cập nhật hàm tạo dataset
class ForestDataset(Dataset):
    def __init__(self, csv_path, image_folder, transform=None):
        self.data = pd.read_csv(csv_path)
        self.image_folder = image_folder
        self.transform = transform
        
        # Thêm các cột mới từ GEDI
        self.features = [
            'agbd', 'agbd_se', 'l2_quality_flag', 'sensitivity',
            'rh100', 'rh95', 'rh75', 'cover', 'pai',
            'degrade_flag', 'beam_type'
        ]
        
        # Chuyển đổi kiểu dữ liệu
        for col in self.features:
            self.data[col] = pd.to_numeric(self.data[col], errors='coerce')
        
        # Xử lý missing values
        self.data = self.data.dropna(subset=self.features)
        
        # Chuẩn hóa dữ liệu
        self.scaler = MinMaxScaler()
        self.data[self.features] = self.scaler.fit_transform(self.data[self.features])
        
        self.num_images = min(500, len(self.data))

    def __len__(self):
        return self.num_images

    def __getitem__(self, idx):
        image_path = os.path.join(self.image_folder, f"image_{idx}.png")
        metadata_path = image_path.replace('.png', '_metadata.json')
        
        # Đọc ảnh
        image = Image.open(image_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        
        # Đọc metadata
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        # Tạo label từ metadata
        label = torch.tensor([metadata[feat] for feat in self.features], dtype=torch.float32)
        
        return image, label

# ✅ Khởi tạo dataset
dataset = ForestDataset(
    csv_path="/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv",
    image_folder="/content/drive/MyDrive/forest-ai/spectral_images",
    transform=transform
)

# ✅ Chia dataset thành train, validation, test
total_size = len(dataset)
train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

# ✅ Tạo DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

print(f"📌 Train set: {len(train_dataset)} samples")
print(f"📌 Validation set: {len(val_dataset)} samples")
print(f"📌 Test set: {len(test_dataset)} samples")

"""#Huấn luyện ViT"""

from transformers import ViTModel
import torch.nn as nn
import torch.optim as optim

# ✅ Load model ViT gốc
vit_base = ViTModel.from_pretrained("google/vit-base-patch16-224")

# ✅ Tạo model custom cho hồi quy
class ViTRegressor(nn.Module):
    def __init__(self, vit_model, num_outputs):
        super(ViTRegressor, self).__init__()
        self.vit = vit_model
        self.regressor = nn.Linear(768, num_outputs)

    def forward(self, x):
        outputs = self.vit(x).last_hidden_state[:, 0, :]
        return self.regressor(outputs)

# ✅ Khởi tạo model với 5 đầu ra
num_outputs = 5
model = ViTRegressor(vit_base, num_outputs)

# ✅ Cấu hình optimizer & loss function
optimizer = optim.Adam(model.parameters(), lr=1e-4)
criterion = nn.MSELoss()

# ✅ Đưa model lên GPU nếu có
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# ✅ Train loop
epochs= 50
for epoch in range(epochs):
    model.train()
    total_loss = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_train_loss = total_loss / len(train_loader)

    # ✅ **Validation sau mỗi epoch**
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

    avg_val_loss = val_loss / len(val_loader)

    print(f"✅ Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)

        all_preds.append(outputs.cpu().numpy())
        all_labels.append(labels.cpu().numpy())

# Chuyển về numpy
all_preds = np.vstack(all_preds)
all_labels = np.vstack(all_labels)

# Tính MAE & RMSE
mae = mean_absolute_error(all_labels, all_preds)
rmse = np.sqrt(mean_squared_error(all_labels, all_preds))

print(f"📌 MAE: {mae:.4f}")
print(f"📌 RMSE: {rmse:.4f}")

"""#Lưu mô hình & Load lại"""

model_save_path = "/content/drive/MyDrive/forest-ai/vit_forest.pth"
torch.save(model.state_dict(), model_save_path)
print(f"✅ Model đã được lưu tại {model_save_path}")

model.load_state_dict(torch.load(model_save_path))
model.eval()  # Đặt model về chế độ inference
print("✅ Model đã load lại thành công!")

"""#Kiểm tra độ chính xác của model trên tập test"""

def predict_image(image_path):
    image = Image.open(image_path).convert("RGB")  # Mở ảnh
    image = transform(image).unsqueeze(0).to(device)  # Áp dụng transform & thêm batch dimension

    model.eval()
    with torch.no_grad():
        pred = model(image)  # 🔹 Không cần `.logits`

    return pred.cpu().numpy()[0]  # Trả về kết quả dưới dạng numpy array

# 📌 Chạy thử trên một ảnh mới
test_image = "/content/drive/MyDrive/forest-ai/spectral_images/image_10.png"
prediction = predict_image(test_image)

print("📌 Dự đoán sinh khối:", prediction)

"""#So sánh giá trị thực tế vs dự đoán"""

import torch
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm  # Tiến trình chạy

all_labels = []
all_preds = []

def predict_image(image_tensor):
    image = image_tensor.unsqueeze(0).to(device)  # 🔹 Thêm batch dimension & đưa vào GPU (nếu có)

    model.eval()
    with torch.no_grad():
        pred = model(image)

    return pred.cpu().numpy()[0]  # Trả về numpy array

# 📌 Sửa vòng lặp test
for image_tensor, label in tqdm(test_dataset):
    pred = predict_image(image_tensor)  # 🔹 Truyền trực tiếp tensor thay vì đường dẫn ảnh

    all_labels.append(label.numpy())  # Chuyển label thành numpy array
    all_preds.append(pred)


print("✅ Số lượng mẫu test:", len(all_labels))
print("📌 Ground Truth:", all_labels[:5])  # In thử 5 mẫu đầu
print("📌 Predictions:", all_preds[:5])  # In thử 5 dự đoán đầu

import numpy as np
import matplotlib.pyplot as plt

# Chuyển danh sách thành numpy array
all_labels = np.array(all_labels)
all_preds = np.array(all_preds)

# Vẽ scatter plot
plt.figure(figsize=(6,6))
plt.scatter(all_labels, all_preds, alpha=0.5, color="blue", label="Dự đoán của mô hình")

# Vẽ đường y = x
plt.plot([all_labels.min(), all_labels.max()], [all_labels.min(), all_labels.max()], 'r--', label="Dự đoán hoàn hảo (y=x)")

# Thêm tiêu đề và nhãn trục
plt.xlabel("Ground Truth (AGBD)")
plt.ylabel("Predicted (AGBD)")
plt.title("So sánh Ground Truth vs Dự đoán")

# Hiển thị chú thích
plt.legend()

# Hiển thị biểu đồ
plt.show()

"""#kiểm tra dataset

"""

import matplotlib.pyplot as plt
all_labels = np.ravel(all_labels)  # Chắc chắn thành mảng 1D

plt.hist(all_labels, bins=20, color="blue", alpha=0.7)
plt.xlabel("Ground Truth (AGBD)")
plt.ylabel("Số lượng mẫu")
plt.title("Phân bố Ground Truth")
plt.show()

import numpy as np

print("Min:", np.min(all_labels))
print("Max:", np.max(all_labels))
print("Mean:", np.mean(all_labels))
print("Median:", np.median(all_labels))
print("Unique values:", np.unique(all_labels))

from scipy.interpolate import interp1d
import numpy as np
import matplotlib.pyplot as plt

# Giả sử all_labels là danh sách giá trị gốc
x_original = np.linspace(0, len(all_labels) - 1, num=len(all_labels))  # Chỉ số gốc
interp_func = interp1d(x_original, all_labels, kind='linear')  # Hàm nội suy tuyến tính

# Tạo dữ liệu nội suy mịn hơn
x_interp = np.linspace(0, len(all_labels) - 1, num=500)  # Tăng mật độ dữ liệu
interp_labels = interp_func(x_interp)

# Vẽ histogram
plt.hist(interp_labels, bins=20, color="blue", alpha=0.7)
plt.xlabel("Giá trị nội suy")
plt.ylabel("Tần suất")
plt.title("Histogram dữ liệu sau nội suy")
plt.show()

plt.hist(all_labels, bins=20, color="red", alpha=0.7)
plt.xlabel("Giá trị Ground Truth (AGBD)")
plt.ylabel("Tần suất")
plt.title("Histogram dữ liệu gốc")
plt.show()

# ✅ Cải tiến model architecture
class SpectralAttention(nn.Module):
    def __init__(self, num_bands):
        super().__init__()
        self.attention = nn.Sequential(
            nn.Linear(num_bands, num_bands//2),
            nn.ReLU(),
            nn.Linear(num_bands//2, num_bands),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # x: [batch, channels, height, width]
        attention = self.attention(x.mean(dim=[2,3]))
        return x * attention.unsqueeze(-1).unsqueeze(-1)

class EnhancedFeatures(nn.Module):
    def __init__(self):
        super().__init__()
        self.ndvi = lambda x: (x[:,3] - x[:,2]) / (x[:,3] + x[:,2] + 1e-6)
        self.evi = lambda x: 2.5 * (x[:,3] - x[:,2]) / (x[:,3] + 6*x[:,2] - 7.5*x[:,0] + 1)
        
    def forward(self, x):
        # x: [batch, channels, height, width]
        ndvi = self.ndvi(x)
        evi = self.evi(x)
        return torch.cat([x, ndvi.unsqueeze(1), evi.unsqueeze(1)], dim=1)

class HybridForestModel(nn.Module):
    def __init__(self, num_outputs=5):
        super().__init__()
        
        # CNN để trích xuất đặc trưng cấp thấp
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        
        # ViT để học các tương tác dài hạn
        self.vit = ViTModel.from_pretrained("google/vit-base-patch16-224")
        
        # Spectral attention
        self.spectral_attention = SpectralAttention(num_bands=5)  # 3 RGB + NDVI + EVI
        
        # Enhanced features
        self.enhanced_features = EnhancedFeatures()
        
        # Fusion layers
        self.fusion = nn.Sequential(
            nn.Linear(768 + 128*56*56, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # Regressor
        self.regressor = nn.Sequential(
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, num_outputs)
        )
        
    def forward(self, x):
        # CNN features
        cnn_features = self.cnn(x)
        cnn_features = cnn_features.view(cnn_features.size(0), -1)
        
        # ViT features
        vit_features = self.vit(x).last_hidden_state[:, 0, :]
        
        # Enhanced features
        enhanced = self.enhanced_features(x)
        enhanced = self.spectral_attention(enhanced)
        enhanced = enhanced.mean(dim=[2,3])
        
        # Fusion
        combined = torch.cat([cnn_features, vit_features, enhanced], dim=1)
        features = self.fusion(combined)
        
        # Regression
        output = self.regressor(features)
        
        return output

# ✅ Cải tiến loss function
class TotalLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.mse_loss = nn.MSELoss()
        self.l1_loss = nn.L1Loss()
        
    def forward(self, pred, target):
        mse_loss = self.mse_loss(pred, target)
        l1_loss = self.l1_loss(pred, target)
        
        # Thêm loss cho các đặc trưng phụ
        spectral_loss = self.l1_loss(pred[:,:3], target[:,:3])
        structural_loss = self.l1_loss(pred[:,3:], target[:,3:])
        
        return mse_loss + 0.5*l1_loss + 0.3*spectral_loss + 0.2*structural_loss

# ✅ Cải tiến training loop
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50):
    best_val_loss = float('inf')
    patience = 5
    counter = 0
    
    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        avg_train_loss = train_loss / len(train_loader)
        
        # Validation phase
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
        
        avg_val_loss = val_loss / len(val_loader)
        
        # Learning rate scheduling
        scheduler.step(avg_val_loss)
        
        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"Train Loss: {avg_train_loss:.4f}")
        print(f"Val Loss: {avg_val_loss:.4f}")
        print(f"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}")
        
        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            counter = 0
            torch.save(model.state_dict(), "best_model.pth")
        else:
            counter += 1
            if counter >= patience:
                print("Early stopping triggered")
                break
    
    # Load best model
    model.load_state_dict(torch.load("best_model.pth"))
    return model

# ✅ Khởi tạo model và training
if __name__ == "__main__":
    # Khởi tạo device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Khởi tạo model
    model = HybridForestModel(num_outputs=5).to(device)
    
    # Khởi tạo loss function
    criterion = TotalLoss()
    
    # Khởi tạo optimizer với weight decay
    optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)
    
    # Khởi tạo learning rate scheduler
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='min',
        factor=0.5,
        patience=3,
        verbose=True
    )
    
    # Khởi tạo dataset
    dataset = ForestDataset(
        csv_path="/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv",
        image_folder="/content/drive/MyDrive/forest-ai/spectral_images",
        transform=transform
    )
    
    # Chia dataset
    train_size = int(0.7 * len(dataset))
    val_size = int(0.15 * len(dataset))
    test_size = len(dataset) - train_size - val_size
    
    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])
    
    # Tạo dataloader
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
    
    # Train model
    model = train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        num_epochs=50
    )
    
    # Evaluate model
    model.eval()
    test_loss = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item()
            
            all_preds.append(outputs.cpu().numpy())
            all_labels.append(labels.cpu().numpy())
    
    # Tính metrics
    all_preds = np.vstack(all_preds)
    all_labels = np.vstack(all_labels)
    
    mae = np.mean(np.abs(all_preds - all_labels))
    rmse = np.sqrt(np.mean((all_preds - all_labels)**2))
    
    print(f"Test Loss: {test_loss/len(test_loader):.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RMSE: {rmse:.4f}")
    
    # Visualize results
    plt.figure(figsize=(10, 5))
    plt.scatter(all_labels, all_preds, alpha=0.5)
    plt.plot([all_labels.min(), all_labels.max()], [all_labels.min(), all_labels.max()], 'r--')
    plt.xlabel('Ground Truth')
    plt.ylabel('Predictions')
    plt.title('Ground Truth vs Predictions')
    plt.show()