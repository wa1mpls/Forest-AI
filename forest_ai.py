# -*- coding: utf-8 -*-
"""forest AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rGU4I-aIlZEEl79XDN2FeHK539RaP6eo

#C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng
"""

!pip install torch torchvision transformers geemap datasets earthengine-api

"""#C√†i ƒë·∫∑t th∆∞ vi·ªán"""

import ee
import torch
import torchvision.transforms as transforms
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from torch.utils.data import Dataset, DataLoader, random_split
from transformers import ViTModel
import torch.nn as nn
import torch.optim as optim
import geemap
import os
from google.colab import drive

"""#L·∫•y d·ªØ li·ªáu ·∫£nh v·ªá tinh & d·ªØ li·ªáu th·ª±c ƒë·ªãa t·ª´ Google Earth Engine"""

!pip install earthengine-api geemap

import ee

# X√°c th·ª±c t√†i kho·∫£n (s·∫Ω hi·ªÉn th·ªã link, b·∫°n c·∫ßn ƒëƒÉng nh·∫≠p v√†o t√†i kho·∫£n Google ƒë·ªÉ l·∫•y m√£)
ee.Authenticate()

# Kh·ªüi t·∫°o l·∫°i Earth Engine v·ªõi project ID
ee.Initialize(project='ee-ngonguyenthanhthanh00')

# ‚úÖ Mount Google Drive
drive.mount('/content/drive')
WORKING_DIR = '/content/drive/MyDrive/forest-ai'

# Commented out IPython magic to ensure Python compatibility.
import os

if not os.path.exists(WORKING_DIR):
    os.makedirs(WORKING_DIR)

# %cd $WORKING_DIR

!pip install geemap

"""#Gi·∫£i ph√°p thay th·∫ø"""

import ee
import geemap

# ‚úÖ Ch·ªçn khu v·ª±c nghi√™n c·ª©u (Amazon)
region = ee.Geometry.Rectangle([-75.0, -15.0, -50.0, 5.0])

# ‚úÖ L·ªçc danh s√°ch b·∫£ng GEDI L4A trong khu v·ª±c Amazon
gedi_index = ee.FeatureCollection("LARSE/GEDI/GEDI04_A_002_INDEX")
filtered_tables = gedi_index.filterBounds(region)
list_tables = filtered_tables.aggregate_array('table_id').getInfo()

print(f"üìå T·ªïng s·ªë b·∫£ng GEDI L4A trong v√πng nghi√™n c·ª©u: {len(list_tables)}")
if len(list_tables) == 0:
    raise ValueError("‚ùå Kh√¥ng c√≥ b·∫£ng GEDI n√†o n·∫±m trong v√πng nghi√™n c·ª©u!")

# ‚úÖ Ch·ªçn b·∫£ng c√≥ nhi·ªÅu d·ªØ li·ªáu `agbd` nh·∫•t
best_table = None
best_count = 0
best_table_name = None

for table_name in list_tables:
    print(f"üìå ƒêang ki·ªÉm tra b·∫£ng: {table_name}")

    try:
        temp_table = ee.FeatureCollection(table_name)
        valid_table = temp_table.filter(ee.Filter.notNull(['agbd']))  # üîπ Ch·ªâ gi·ªØ ƒëi·ªÉm c√≥ `agbd`
        valid_count = valid_table.size().getInfo()

        print(f"üìå S·ªë l∆∞·ª£ng ƒëi·ªÉm c√≥ `agbd`: {valid_count}")

        if valid_count > best_count:
            best_count = valid_count
            best_table = valid_table
            best_table_name = table_name

        if best_count >= 10000:  # D·ª´ng ngay khi c√≥ ƒë·ªß 10.000 ƒëi·ªÉm
            break

    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i b·∫£ng {table_name}: {e}")
        continue

# ‚úÖ **Ki·ªÉm tra n·∫øu kh√¥ng c√≥ b·∫£ng n√†o c√≥ d·ªØ li·ªáu**
if best_table is None or best_count == 0:
    raise ValueError("‚ùå Kh√¥ng c√≥ b·∫£ng GEDI n√†o ch·ª©a d·ªØ li·ªáu `agbd` trong v√πng nghi√™n c·ª©u!")

print(f"‚úÖ Ch·ªçn b·∫£ng {best_table_name} c√≥ nhi·ªÅu d·ªØ li·ªáu nh·∫•t, v·ªõi {best_count} ƒëi·ªÉm.")

# ‚úÖ **Ch·ªçn ƒë√∫ng c√°c thu·ªôc t√≠nh quan tr·ªçng**
selected_columns = [
    'lon_lowestmode_a1',  # Kinh ƒë·ªô
    'lat_lowestmode_a1',  # Vƒ© ƒë·ªô
    'agbd',  # T·ªïng sinh kh·ªëi
    'agbd_se',  # ƒê·ªô kh√¥ng ch·∫Øc ch·∫Øn c·ªßa sinh kh·ªëi
    'l2_quality_flag',  # C·ªù ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu
    'sensitivity',  # ƒê·ªô nh·∫°y t√≠n hi·ªáu GEDI
    'landsat_treecover'  # M·∫≠t ƒë·ªô t√°n c√¢y theo Landsat
]

# ‚úÖ **Ki·ªÉm tra l·∫°i c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng**
first_feature = best_table.first()
gedi_columns = first_feature.propertyNames().getInfo()
valid_columns = [col for col in selected_columns if col in gedi_columns]
print("üìå C√°c c·ªôt h·ª£p l·ªá s·∫Ω ƒë∆∞·ª£c xu·∫•t:", valid_columns)

# ‚úÖ **Ch·ªçn v√† gi·ªõi h·∫°n s·ªë ƒëi·ªÉm**
gedi_filtered = best_table.select(valid_columns).limit(10000)

# ‚úÖ **Xu·∫•t d·ªØ li·ªáu ra Google Drive**
output_path = "/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv"
geemap.ee_export_vector(gedi_filtered, filename=output_path)

print(f"‚úÖ Xu·∫•t d·ªØ li·ªáu th√†nh c√¥ng! File ƒë∆∞·ª£c l∆∞u t·∫°i: {output_path}")

"""#Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu"""

import os
print(os.getcwd())  # In ra ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c hi·ªán t·∫°i

import os
print(os.listdir())  # Li·ªát k√™ t·∫•t c·∫£ c√°c file trong th∆∞ m·ª•c

import os
print(os.path.exists("GEDI_L4A_Amazon.csv"))  # N·∫øu True th√¨ file c√≥ t·ªìn t·∫°i, False th√¨ ch∆∞a c√≥ file

import torch
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# ‚úÖ ƒê·ªçc d·ªØ li·ªáu
df = pd.read_csv("/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv")

# ‚úÖ Ki·ªÉm tra k√≠ch th∆∞·ªõc d·ªØ li·ªáu tr∆∞·ªõc khi dropna
print("üìå K√≠ch th∆∞·ªõc d·ªØ li·ªáu ban ƒë·∫ßu:", df.shape)

# ‚úÖ Ch·ªâ drop NaN trong c·ªôt target, kh√¥ng drop to√†n b·ªô
df = df.dropna(subset=['agbd'])

# ‚úÖ Ki·ªÉm tra n·∫øu file r·ªóng
if df.shape[0] == 0:
    raise ValueError("‚ùå D·ªØ li·ªáu r·ªóng! Ki·ªÉm tra file CSV ho·∫∑c dropna() ƒë√£ x√≥a h·∫øt d·ªØ li·ªáu.")

print("üìå K√≠ch th∆∞·ªõc d·ªØ li·ªáu sau khi x·ª≠ l√Ω:", df.shape)

# ‚úÖ Ch·ªçn ƒë·∫∑c tr∆∞ng v√† nh√£n
features = ['lon_lowestmode_a1', 'lat_lowestmode_a1', 'agbd', 'agbd_se', 'l2_quality_flag', 'sensitivity', 'landsat_treecover']
target = 'agbd'

# ‚úÖ Ki·ªÉm tra n·∫øu c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng
for col in features + [target]:
    if col not in df.columns:
        raise ValueError(f"‚ùå C·ªôt '{col}' kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu!")

# ‚úÖ Chia d·ªØ li·ªáu
X = df[features].values
y = df[target].values
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# ‚úÖ Chuy·ªÉn ƒë·ªïi th√†nh Tensor
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)
y_valid_tensor = torch.tensor(y_valid, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

print("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!")

import ee
import geemap
import requests
import os
from PIL import Image
import pandas as pd


# ‚úÖ ƒê·ªçc d·ªØ li·ªáu GEDI t·ª´ CSV
gedi_df = pd.read_csv("/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv")

# ‚úÖ Ch·ªçn 100 ƒëi·ªÉm ƒë·ªÉ ki·ªÉm tra tr∆∞·ªõc
gedi_df = gedi_df.sample(n=500, random_state=42)

# ‚úÖ T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh
output_dir = "/content/drive/MyDrive/forest-ai/spectral_images"
os.makedirs(output_dir, exist_ok=True)

# ‚úÖ C·∫•u h√¨nh hi·ªÉn th·ªã ·∫£nh Sentinel-2
viz_params = {
    "bands": ["B4", "B3", "B2"],  # üîπ Ch·ªçn 3 k√™nh RGB
    "min": 0,
    "max": 3000,  # üîπ Chu·∫©n h√≥a gi√° tr·ªã pixel
    "gamma": 1.5
}

# ‚úÖ Th√™m c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
!pip install h5py netCDF4

import h5py
import netCDF4
from datetime import datetime, timedelta

# ‚úÖ ƒê·ªãnh nghƒ©a c√°c h√†m l·∫•y d·ªØ li·ªáu GEDI
def get_gedi_l4a_data(point, date_range):
    """L·∫•y d·ªØ li·ªáu GEDI L4A cho m·ªôt ƒëi·ªÉm"""
    gedi_l4a = ee.ImageCollection("LARSE/GEDI/GEDI04_A_002_MONTHLY")
    filtered = gedi_l4a.filterBounds(point).filterDate(date_range[0], date_range[1])
    
    # L·∫•y c√°c thu·ªôc t√≠nh quan tr·ªçng
    properties = {
        'agbd': filtered.select('agbd').mean(),
        'agbd_se': filtered.select('agbd_se').mean(),
        'l2_quality_flag': filtered.select('l2_quality_flag').mode(),
        'sensitivity': filtered.select('sensitivity').mean(),
        'degrade_flag': filtered.select('degrade_flag').mode(),
        'beam_type': filtered.select('beam_type').mode()
    }
    
    return properties

def get_gedi_l2a_data(point, date_range):
    """L·∫•y d·ªØ li·ªáu GEDI L2A cho m·ªôt ƒëi·ªÉm"""
    gedi_l2a = ee.ImageCollection("LARSE/GEDI/GEDI02_A_002_MONTHLY")
    filtered = gedi_l2a.filterBounds(point).filterDate(date_range[0], date_range[1])
    
    # L·∫•y c√°c thu·ªôc t√≠nh chi·ªÅu cao
    properties = {
        'rh100': filtered.select('rh100').mean(),
        'rh95': filtered.select('rh95').mean(),
        'rh75': filtered.select('rh75').mean()
    }
    
    return properties

def get_gedi_l2b_data(point, date_range):
    """L·∫•y d·ªØ li·ªáu GEDI L2B cho m·ªôt ƒëi·ªÉm"""
    gedi_l2b = ee.ImageCollection("LARSE/GEDI/GEDI02_B_002_MONTHLY")
    filtered = gedi_l2b.filterBounds(point).filterDate(date_range[0], date_range[1])
    
    # L·∫•y c√°c thu·ªôc t√≠nh ƒë·ªô che ph·ªß
    properties = {
        'cover': filtered.select('cover').mean(),
        'pai': filtered.select('pai').mean()
    }
    
    return properties

# ‚úÖ C·∫≠p nh·∫≠t h√†m l·∫•y ·∫£nh Sentinel-2
def get_sentinel_image(lat, lon, output_path, date_range):
    point = ee.Geometry.Point([lon, lat])
    
    # L·∫•y ·∫£nh Sentinel-2
    image = (
        ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
        .filterBounds(point)
        .filterDate(date_range[0], date_range[1])
        .filter(ee.Filter.lt("CLOUDY_PIXEL_PERCENTAGE", 5))
        .median()
        .clip(point.buffer(2500))
    )
    
    # L·∫•y d·ªØ li·ªáu GEDI
    gedi_l4a = get_gedi_l4a_data(point, date_range)
    gedi_l2a = get_gedi_l2a_data(point, date_range)
    gedi_l2b = get_gedi_l2b_data(point, date_range)
    
    # K·∫øt h·ª£p t·∫•t c·∫£ d·ªØ li·ªáu
    all_data = {**gedi_l4a, **gedi_l2a, **gedi_l2b}
    
    try:
        # L·∫•y ·∫£nh Sentinel-2
        url = image.getThumbURL({"dimensions": "256x256", "region": point.buffer(2500), **viz_params})
        response = requests.get(url, stream=True)
        
        if response.status_code == 200:
            # L∆∞u ·∫£nh
            with open(output_path, "wb") as f:
                f.write(response.content)
            
            # L∆∞u metadata GEDI
            metadata_path = output_path.replace('.png', '_metadata.json')
            with open(metadata_path, 'w') as f:
                json.dump(all_data, f)
            
            print(f"‚úÖ ƒê√£ l∆∞u {output_path} v√† metadata")
        else:
            print(f"‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c ·∫£nh t·ª´ {url}")
            
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y d·ªØ li·ªáu t·∫°i ({lat}, {lon}): {e}")

# ‚úÖ C·∫≠p nh·∫≠t h√†m t·∫°o dataset
class ForestDataset(Dataset):
    def __init__(self, csv_path, image_folder, transform=None):
        self.data = pd.read_csv(csv_path)
        self.image_folder = image_folder
        self.transform = transform
        
        # Th√™m c√°c c·ªôt m·ªõi t·ª´ GEDI
        self.features = [
            'agbd', 'agbd_se', 'l2_quality_flag', 'sensitivity',
            'rh100', 'rh95', 'rh75', 'cover', 'pai',
            'degrade_flag', 'beam_type'
        ]
        
        # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
        for col in self.features:
            self.data[col] = pd.to_numeric(self.data[col], errors='coerce')
        
        # X·ª≠ l√Ω missing values
        self.data = self.data.dropna(subset=self.features)
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu
        self.scaler = MinMaxScaler()
        self.data[self.features] = self.scaler.fit_transform(self.data[self.features])
        
        self.num_images = min(500, len(self.data))

    def __len__(self):
        return self.num_images

    def __getitem__(self, idx):
        image_path = os.path.join(self.image_folder, f"image_{idx}.png")
        metadata_path = image_path.replace('.png', '_metadata.json')
        
        # ƒê·ªçc ·∫£nh
        image = Image.open(image_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        
        # ƒê·ªçc metadata
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        # T·∫°o label t·ª´ metadata
        label = torch.tensor([metadata[feat] for feat in self.features], dtype=torch.float32)
        
        return image, label

# ‚úÖ Kh·ªüi t·∫°o dataset
dataset = ForestDataset(
    csv_path="/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv",
    image_folder="/content/drive/MyDrive/forest-ai/spectral_images",
    transform=transform
)

# ‚úÖ Chia dataset th√†nh train, validation, test
total_size = len(dataset)
train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

# ‚úÖ T·∫°o DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

print(f"üìå Train set: {len(train_dataset)} samples")
print(f"üìå Validation set: {len(val_dataset)} samples")
print(f"üìå Test set: {len(test_dataset)} samples")

"""#Hu·∫•n luy·ªán ViT"""

from transformers import ViTModel
import torch.nn as nn
import torch.optim as optim

# ‚úÖ Load model ViT g·ªëc
vit_base = ViTModel.from_pretrained("google/vit-base-patch16-224")

# ‚úÖ T·∫°o model custom cho h·ªìi quy
class ViTRegressor(nn.Module):
    def __init__(self, vit_model, num_outputs):
        super(ViTRegressor, self).__init__()
        self.vit = vit_model
        self.regressor = nn.Linear(768, num_outputs)

    def forward(self, x):
        outputs = self.vit(x).last_hidden_state[:, 0, :]
        return self.regressor(outputs)

# ‚úÖ Kh·ªüi t·∫°o model v·ªõi 5 ƒë·∫ßu ra
num_outputs = 5
model = ViTRegressor(vit_base, num_outputs)

# ‚úÖ C·∫•u h√¨nh optimizer & loss function
optimizer = optim.Adam(model.parameters(), lr=1e-4)
criterion = nn.MSELoss()

# ‚úÖ ƒê∆∞a model l√™n GPU n·∫øu c√≥
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# ‚úÖ Train loop
epochs= 50
for epoch in range(epochs):
    model.train()
    total_loss = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_train_loss = total_loss / len(train_loader)

    # ‚úÖ **Validation sau m·ªói epoch**
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

    avg_val_loss = val_loss / len(val_loader)

    print(f"‚úÖ Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)

        all_preds.append(outputs.cpu().numpy())
        all_labels.append(labels.cpu().numpy())

# Chuy·ªÉn v·ªÅ numpy
all_preds = np.vstack(all_preds)
all_labels = np.vstack(all_labels)

# T√≠nh MAE & RMSE
mae = mean_absolute_error(all_labels, all_preds)
rmse = np.sqrt(mean_squared_error(all_labels, all_preds))

print(f"üìå MAE: {mae:.4f}")
print(f"üìå RMSE: {rmse:.4f}")

"""#L∆∞u m√¥ h√¨nh & Load l·∫°i"""

model_save_path = "/content/drive/MyDrive/forest-ai/vit_forest.pth"
torch.save(model.state_dict(), model_save_path)
print(f"‚úÖ Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i {model_save_path}")

model.load_state_dict(torch.load(model_save_path))
model.eval()  # ƒê·∫∑t model v·ªÅ ch·∫ø ƒë·ªô inference
print("‚úÖ Model ƒë√£ load l·∫°i th√†nh c√¥ng!")

"""#Ki·ªÉm tra ƒë·ªô ch√≠nh x√°c c·ªßa model tr√™n t·∫≠p test"""

def predict_image(image_path):
    image = Image.open(image_path).convert("RGB")  # M·ªü ·∫£nh
    image = transform(image).unsqueeze(0).to(device)  # √Åp d·ª•ng transform & th√™m batch dimension

    model.eval()
    with torch.no_grad():
        pred = model(image)  # üîπ Kh√¥ng c·∫ßn `.logits`

    return pred.cpu().numpy()[0]  # Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng numpy array

# üìå Ch·∫°y th·ª≠ tr√™n m·ªôt ·∫£nh m·ªõi
test_image = "/content/drive/MyDrive/forest-ai/spectral_images/image_10.png"
prediction = predict_image(test_image)

print("üìå D·ª± ƒëo√°n sinh kh·ªëi:", prediction)

"""#So s√°nh gi√° tr·ªã th·ª±c t·∫ø vs d·ª± ƒëo√°n"""

import torch
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm  # Ti·∫øn tr√¨nh ch·∫°y

all_labels = []
all_preds = []

def predict_image(image_tensor):
    image = image_tensor.unsqueeze(0).to(device)  # üîπ Th√™m batch dimension & ƒë∆∞a v√†o GPU (n·∫øu c√≥)

    model.eval()
    with torch.no_grad():
        pred = model(image)

    return pred.cpu().numpy()[0]  # Tr·∫£ v·ªÅ numpy array

# üìå S·ª≠a v√≤ng l·∫∑p test
for image_tensor, label in tqdm(test_dataset):
    pred = predict_image(image_tensor)  # üîπ Truy·ªÅn tr·ª±c ti·∫øp tensor thay v√¨ ƒë∆∞·ªùng d·∫´n ·∫£nh

    all_labels.append(label.numpy())  # Chuy·ªÉn label th√†nh numpy array
    all_preds.append(pred)


print("‚úÖ S·ªë l∆∞·ª£ng m·∫´u test:", len(all_labels))
print("üìå Ground Truth:", all_labels[:5])  # In th·ª≠ 5 m·∫´u ƒë·∫ßu
print("üìå Predictions:", all_preds[:5])  # In th·ª≠ 5 d·ª± ƒëo√°n ƒë·∫ßu

import numpy as np
import matplotlib.pyplot as plt

# Chuy·ªÉn danh s√°ch th√†nh numpy array
all_labels = np.array(all_labels)
all_preds = np.array(all_preds)

# V·∫Ω scatter plot
plt.figure(figsize=(6,6))
plt.scatter(all_labels, all_preds, alpha=0.5, color="blue", label="D·ª± ƒëo√°n c·ªßa m√¥ h√¨nh")

# V·∫Ω ƒë∆∞·ªùng y = x
plt.plot([all_labels.min(), all_labels.max()], [all_labels.min(), all_labels.max()], 'r--', label="D·ª± ƒëo√°n ho√†n h·∫£o (y=x)")

# Th√™m ti√™u ƒë·ªÅ v√† nh√£n tr·ª•c
plt.xlabel("Ground Truth (AGBD)")
plt.ylabel("Predicted (AGBD)")
plt.title("So s√°nh Ground Truth vs D·ª± ƒëo√°n")

# Hi·ªÉn th·ªã ch√∫ th√≠ch
plt.legend()

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
plt.show()

"""#ki·ªÉm tra dataset

"""

import matplotlib.pyplot as plt
all_labels = np.ravel(all_labels)  # Ch·∫Øc ch·∫Øn th√†nh m·∫£ng 1D

plt.hist(all_labels, bins=20, color="blue", alpha=0.7)
plt.xlabel("Ground Truth (AGBD)")
plt.ylabel("S·ªë l∆∞·ª£ng m·∫´u")
plt.title("Ph√¢n b·ªë Ground Truth")
plt.show()

import numpy as np

print("Min:", np.min(all_labels))
print("Max:", np.max(all_labels))
print("Mean:", np.mean(all_labels))
print("Median:", np.median(all_labels))
print("Unique values:", np.unique(all_labels))

from scipy.interpolate import interp1d
import numpy as np
import matplotlib.pyplot as plt

# Gi·∫£ s·ª≠ all_labels l√† danh s√°ch gi√° tr·ªã g·ªëc
x_original = np.linspace(0, len(all_labels) - 1, num=len(all_labels))  # Ch·ªâ s·ªë g·ªëc
interp_func = interp1d(x_original, all_labels, kind='linear')  # H√†m n·ªôi suy tuy·∫øn t√≠nh

# T·∫°o d·ªØ li·ªáu n·ªôi suy m·ªãn h∆°n
x_interp = np.linspace(0, len(all_labels) - 1, num=500)  # TƒÉng m·∫≠t ƒë·ªô d·ªØ li·ªáu
interp_labels = interp_func(x_interp)

# V·∫Ω histogram
plt.hist(interp_labels, bins=20, color="blue", alpha=0.7)
plt.xlabel("Gi√° tr·ªã n·ªôi suy")
plt.ylabel("T·∫ßn su·∫•t")
plt.title("Histogram d·ªØ li·ªáu sau n·ªôi suy")
plt.show()

plt.hist(all_labels, bins=20, color="red", alpha=0.7)
plt.xlabel("Gi√° tr·ªã Ground Truth (AGBD)")
plt.ylabel("T·∫ßn su·∫•t")
plt.title("Histogram d·ªØ li·ªáu g·ªëc")
plt.show()

# ‚úÖ C·∫£i ti·∫øn model architecture
class SpectralAttention(nn.Module):
    def __init__(self, num_bands):
        super().__init__()
        self.attention = nn.Sequential(
            nn.Linear(num_bands, num_bands//2),
            nn.ReLU(),
            nn.Linear(num_bands//2, num_bands),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # x: [batch, channels, height, width]
        attention = self.attention(x.mean(dim=[2,3]))
        return x * attention.unsqueeze(-1).unsqueeze(-1)

class EnhancedFeatures(nn.Module):
    def __init__(self):
        super().__init__()
        self.ndvi = lambda x: (x[:,3] - x[:,2]) / (x[:,3] + x[:,2] + 1e-6)
        self.evi = lambda x: 2.5 * (x[:,3] - x[:,2]) / (x[:,3] + 6*x[:,2] - 7.5*x[:,0] + 1)
        
    def forward(self, x):
        # x: [batch, channels, height, width]
        ndvi = self.ndvi(x)
        evi = self.evi(x)
        return torch.cat([x, ndvi.unsqueeze(1), evi.unsqueeze(1)], dim=1)

class HybridForestModel(nn.Module):
    def __init__(self, num_outputs=5):
        super().__init__()
        
        # CNN ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng c·∫•p th·∫•p
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        
        # ViT ƒë·ªÉ h·ªçc c√°c t∆∞∆°ng t√°c d√†i h·∫°n
        self.vit = ViTModel.from_pretrained("google/vit-base-patch16-224")
        
        # Spectral attention
        self.spectral_attention = SpectralAttention(num_bands=5)  # 3 RGB + NDVI + EVI
        
        # Enhanced features
        self.enhanced_features = EnhancedFeatures()
        
        # Fusion layers
        self.fusion = nn.Sequential(
            nn.Linear(768 + 128*56*56, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # Regressor
        self.regressor = nn.Sequential(
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, num_outputs)
        )
        
    def forward(self, x):
        # CNN features
        cnn_features = self.cnn(x)
        cnn_features = cnn_features.view(cnn_features.size(0), -1)
        
        # ViT features
        vit_features = self.vit(x).last_hidden_state[:, 0, :]
        
        # Enhanced features
        enhanced = self.enhanced_features(x)
        enhanced = self.spectral_attention(enhanced)
        enhanced = enhanced.mean(dim=[2,3])
        
        # Fusion
        combined = torch.cat([cnn_features, vit_features, enhanced], dim=1)
        features = self.fusion(combined)
        
        # Regression
        output = self.regressor(features)
        
        return output

# ‚úÖ C·∫£i ti·∫øn loss function
class TotalLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.mse_loss = nn.MSELoss()
        self.l1_loss = nn.L1Loss()
        
    def forward(self, pred, target):
        mse_loss = self.mse_loss(pred, target)
        l1_loss = self.l1_loss(pred, target)
        
        # Th√™m loss cho c√°c ƒë·∫∑c tr∆∞ng ph·ª•
        spectral_loss = self.l1_loss(pred[:,:3], target[:,:3])
        structural_loss = self.l1_loss(pred[:,3:], target[:,3:])
        
        return mse_loss + 0.5*l1_loss + 0.3*spectral_loss + 0.2*structural_loss

# ‚úÖ C·∫£i ti·∫øn training loop
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50):
    best_val_loss = float('inf')
    patience = 5
    counter = 0
    
    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        avg_train_loss = train_loss / len(train_loader)
        
        # Validation phase
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
        
        avg_val_loss = val_loss / len(val_loader)
        
        # Learning rate scheduling
        scheduler.step(avg_val_loss)
        
        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"Train Loss: {avg_train_loss:.4f}")
        print(f"Val Loss: {avg_val_loss:.4f}")
        print(f"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}")
        
        # Early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            counter = 0
            torch.save(model.state_dict(), "best_model.pth")
        else:
            counter += 1
            if counter >= patience:
                print("Early stopping triggered")
                break
    
    # Load best model
    model.load_state_dict(torch.load("best_model.pth"))
    return model

# ‚úÖ Kh·ªüi t·∫°o model v√† training
if __name__ == "__main__":
    # Kh·ªüi t·∫°o device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Kh·ªüi t·∫°o model
    model = HybridForestModel(num_outputs=5).to(device)
    
    # Kh·ªüi t·∫°o loss function
    criterion = TotalLoss()
    
    # Kh·ªüi t·∫°o optimizer v·ªõi weight decay
    optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)
    
    # Kh·ªüi t·∫°o learning rate scheduler
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='min',
        factor=0.5,
        patience=3,
        verbose=True
    )
    
    # Kh·ªüi t·∫°o dataset
    dataset = ForestDataset(
        csv_path="/content/drive/MyDrive/forest-ai/GEDI_L4A_Amazon.csv",
        image_folder="/content/drive/MyDrive/forest-ai/spectral_images",
        transform=transform
    )
    
    # Chia dataset
    train_size = int(0.7 * len(dataset))
    val_size = int(0.15 * len(dataset))
    test_size = len(dataset) - train_size - val_size
    
    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])
    
    # T·∫°o dataloader
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
    
    # Train model
    model = train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        num_epochs=50
    )
    
    # Evaluate model
    model.eval()
    test_loss = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item()
            
            all_preds.append(outputs.cpu().numpy())
            all_labels.append(labels.cpu().numpy())
    
    # T√≠nh metrics
    all_preds = np.vstack(all_preds)
    all_labels = np.vstack(all_labels)
    
    mae = np.mean(np.abs(all_preds - all_labels))
    rmse = np.sqrt(np.mean((all_preds - all_labels)**2))
    
    print(f"Test Loss: {test_loss/len(test_loader):.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RMSE: {rmse:.4f}")
    
    # Visualize results
    plt.figure(figsize=(10, 5))
    plt.scatter(all_labels, all_preds, alpha=0.5)
    plt.plot([all_labels.min(), all_labels.max()], [all_labels.min(), all_labels.max()], 'r--')
    plt.xlabel('Ground Truth')
    plt.ylabel('Predictions')
    plt.title('Ground Truth vs Predictions')
    plt.show()